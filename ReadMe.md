ğŸŒ± Waste-to-Art â€” Full Setup Guide (Beginner Friendly)

This project turns real-world waste images into AI-generated recycled artwork using:

YOLO object detection

Biodegradability classification

Automatic prompt generation

Stable Diffusion image generation

This guide assumes zero prior experience.
Follow each step exactly.

ğŸŸ© 1. Create a New Project Folder

Create a folder anywhere, for example:

WasteToArtProject


Open VS Code

Go to: File â†’ Open Folder â†’ select WasteToArtProject

ğŸŸ© 2. Open the Terminal (PowerShell)

Inside VS Code:

ğŸ‘‰ Press Ctrl + `
Make sure the terminal says:

PS C:\...WasteToArtProject>

ğŸŸ© 3. Clone the Repository Into This Folder

In the terminal, run:

git clone https://github.com/ShifanaKoormath/WasteToArt.git


After cloning:

cd WasteToArt


Your structure now becomes:

WasteToArtProject/
    WasteToArt/   â† cloned repo

ğŸŸ© 4. Download Stable Diffusion WebUI (Intel DirectML Version)

âš ï¸ IMPORTANT
This project works ONLY with the Intel DirectML version of Stable Diffusion
because it's compatible with all GPUs (Intel, AMD, basic laptop GPUs, even some CPUs).

Download here:

https://github.com/lshqqytiger/stable-diffusion-webui-directml

Click:

Code â†’ Download ZIP


Extract the ZIP.

Rename the folder to:

stable-diffusion-webui


Now move this entire folder inside your project folder, like this:

WasteToArtProject/
    WasteToArt/
    stable-diffusion-webui/

ğŸŸ© 5. Download a Stable Diffusion Model File

Stable Diffusion WILL NOT WORK without a model.

Recommended model (simple & lightweight):

ğŸ’¾ v1-5-pruned-emaonly.safetensors
Download:

https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.safetensors

After downloading:

Move it into:

stable-diffusion-webui/models/Stable-diffusion/


Folder must look like:

stable-diffusion-webui/
    models/
        Stable-diffusion/
            v1-5-pruned-emaonly.safetensors

ğŸŸ© 6. Enable API + Safe Precision Settings

Open this file:

stable-diffusion-webui/webui-user.bat


Right-click â†’ Edit

Replace ALL content with:

@echo off
set COMMANDLINE_ARGS=--api --precision full --no-half --no-half-vae
call webui.bat


Save & close.

ğŸŸ© 7. IMPORTANT: Fix Float Precision Errors (Upcast Attention)

After Stable Diffusion launches:

Open the webpage:

http://127.0.0.1:7860


Go to Settings â†’ Optimizations

Enable:

âœ” Upcast cross-attention to float32

Click â€œApply settingsâ€

Click â€œReload UIâ€

This prevents:

RuntimeError: Input type (float) and bias type (Half) should be the same

ğŸŸ© 8. Start Stable Diffusion

Double-click:

stable-diffusion-webui/webui-user.bat


Wait until you see:

Running on local URL: http://127.0.0.1:7860


Keep this window open.

ğŸŸ© 9. Backend Setup

In VS Code terminal:

cd WasteToArt/backend
python -m venv venv


Activate:

venv\Scripts\activate


Install dependencies:

pip install -r requirements.txt


If anything fails:

pip install flask flask-cors ultralytics tensorflow pillow numpy opencv-python sentence-transformers requests

ğŸŸ© 10. Start the Backend Server

In the backend folder:

python server.py


You should see:

Running on http://127.0.0.1:5000


Backend ready âœ”

ğŸŸ© 11. Run the Frontend

No installation required.

Simply:

ğŸ‘‰ Open the folder
ğŸ‘‰ Go to:

WasteToArt/frontend/index.html


ğŸ‘‰ Drag & drop into any browser (Chrome recommended)

Upload an image â†’ the system will:

detect objects

classify biodegradable items

generate a creative prompt

call Stable Diffusion

display final artwork

ğŸŸ¦ 12. How Everything Works Internally

1ï¸âƒ£ Frontend sends uploaded image to backend
2ï¸âƒ£ Backend saves it in /uploads
3ï¸âƒ£ YOLO detects objects â†’ crops saved in /detection/crops
4ï¸âƒ£ Classifier determines biodegradable / non-biodegradable
5ï¸âƒ£ Prompt is automatically generated
6ï¸âƒ£ Backend sends prompt to Stable Diffusion API
7ï¸âƒ£ SD generates artwork â†’ saved in /backend/output
8ï¸âƒ£ Frontend displays final AI art

ğŸŸ¦ 13. Project Folder You Should Have
WasteToArtProject/
â”‚
â”œâ”€â”€ WasteToArt/                     â† cloned project
â”‚   â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ README.md
â”‚
â””â”€â”€ stable-diffusion-webui/         â† Intel DirectML SD version
    â”œâ”€â”€ webui-user.bat
    â””â”€â”€ models/
         â””â”€â”€ Stable-diffusion/
               â””â”€â”€ v1-5-pruned-emaonly.safetensors

ğŸŸ¦ 14. COMMON ISSUES & FIXES
âŒ SD API Not Found (404)

You forgot --api
Fix:

Open webui-user.bat â†’ ensure:

--api

âŒ Float / Half precision error

Fix (we already enabled):

âœ” Upcast cross-attention
âœ” --precision full
âœ” --no-half
âœ” --no-half-vae

âŒ Blank output / no generation

Your model is in the wrong folder.

Model MUST be here:

stable-diffusion-webui/models/Stable-diffusion/

âŒ Backend cannot find Stable Diffusion

Ensure SD is running on 127.0.0.1:7860